\chapter{Ausführung}

    Dieses Kapitel beschreibt die Vorgehensweise von der ersten manuellen Analyse der Daten bis zum fertigen Produkt.
    Als Beispielprodukt für die Klassifizierung wurde eine Senseo Kaffeemaschine gewählt, da durch häufige Benutzung viele Daten erhoben werden können. 
    Außerdem wurde eine Mikrowelle als zweite Gerät mit wenigen Daten gewählt um verschiedene Parameter und Kennzahlen zu vergleichen.
    Hierbei soll die Anzahl der Daten sowie die Klassifikation von mehreren Geräten innerhalb eines Neuronalen Netzes untersucht werden.

\section{Manuelle Analyse} \label{ManuelleAnalyse}

    Zur manuellen Analyse der Daten wird das in \ref{VisualisierungWebApp} beschriebene Tool verwendet.
    Zunächst werden sehr aussagenkräftige Größen wie die Spannung oder die Frequenz der Kaffeemaschine verwendet und mit anderen aktiven Zeiträumen der Kaffeemaschine verglichen.
    Hierbei kann ein sehr spezifischer Verlauf der Spannung erkannt werden.\\ 
    Wie in Schaubild ref{fig:Spannungsverlauf} zu sehen ist, ist die Kurve zu Beginn start fallend und verbleibt dann eine gewissen Zeit auf diesem Tief. 
    nach einem längeren steigenden Abschnitt fällt die Kurve wieder bis der Zubereitungsvorgang beendet wurde und wieder steigt.\\
    \newline
    Diesem Verlauf können nach mehreren Beobachtungen bestimmte Vorgänge einer Kaffeezubereitung zugeordnet werden.
    Zu Beginn der Kaffeezubereitung wird die Kaffeemaschine manuell eingeschaltet. 
    Dies führt automatisch zum erwärmen des Brühwassers, welches dem ersten Fallen der Kurve zugeordnet werden kann. 
    Da dort viel Energie benötigt um das Wasser zu erhitzen steigt der Stromverbrauch der Kaffeemaschine stark an und somit fällt die Netzspannung stark ab.
    Die Netzspannung bleibt solange auf einem gewissen Tiefpunkt mit minmaler Netzschwankung bis das Wasser erwärmt wurde und ein weiterer manueller Schritt zum fortfahren des Prozesses notwendig ist.\\
    Nach Wahl der Tassengröße wird dann der Brühvorgang gestartet. 
    Dabei wird das erhitzte Wasser mit einem gewissen Druck durch einen Kaffeepad gepresst. 
    Da dieser Druck bei der Senseo Kaffeemaschine durch eine elektronische Pumpe erzeugt wird, sinkt demnach die Netzspannung wird ab bis der komplette Kaffee durch gelaufen ist.
    Somit kann die Zweite Tiefpunktphase dem ``Pressvorgang'' der Kaffeemaschine zugeordnet werden.\\
    \newline
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{SpannungsverlaufSenseo1}
        \includegraphics[width=0.8\textwidth]{SpannungsverlaufSenseo2}
        \caption{Spannungsverlauf der Senseo Kaffeemaschine mit einer Klasse von je 3 Datenpunkten zu 2 verschiedenen Zeitpunkten}
        \label{fig:SpannungsverlaufSenseo}
    \end{figure}

    \noindent
    Bei der manuellen Analyse der Mikrowelle können bei Analyse des Spannungs- oder Frequenzverlaufs leider keine hervorstechenden Merkmale oder Gemeinsamkeiten erkannt werden.
    Somit wird die Mikrowelle demnach einen anderen Einfluss auf doe Netzaktivität ausüben.
    Wie bei dem Vergleich der verschiedenen harmonischen Oberwellen zu sehen ist (siehe Schaubild \ref{fig:3OberwelleMikrowelle}), besteht eine große Ähnlichkeit der Kurven der dritten harmonischen Welle.\\
    \newline

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\textwidth]{3OberwelleMikrowelle1}
        \includegraphics[width=0.8\textwidth]{3OberwelleMikrowelle2}
        \caption{Verlauf der 3. harmonischen Oberwelle einer Mikrowelle mit einer Klasse von je 3 Datenpunkten zu 2 verschiedenen Zeitpunkten}
        \label{fig:3OberwelleMikrowelle}
    \end{figure}

    \noindent
    Wie dieser Abschnitt zeigt können schon mit bloßen Auge bestimmte Auswirkungen der verschiedenen Geräte erkannt werden.
    Auch wenn einige Störungen auftreten und den Verlauf verfälschen, sollte es dennoch möglich sein diese Geräte herauszufiltern.
    Weiterführend wird dieser Prozess automatisiert und verbessert um auch trotz großer Störungen, Geräte präzise klassifizieren zu können. 

\section{Vorbereiten der Daten}\label{VorbereitenDerDaten}
    Um die Klassifizierung der Geräte auf neuronalen Netzen abzubilden müssen die vorhandenen Daten in ein geeignetes Format transformiert werden.
    Dabei gibt es verschiedene Vorraussetzungen zu beachten, sowie verschiedene Möglichkeiten die Daten zu transformieren.\\
    
    \noindent
    Bei konventionellen Neuronalen Netzen werden Eigenschaften Objekten zugewiesen, wobei alle Objekte mit denselben Eigenschaften betitelt werden.
    Ein Beispiel dafür sind Tiere, bei denen anhand von Reproduktion oder Atmung in Säugetiere, Vögel, Reptilien, etc. eingeteilt wird. 
    So können spezielle Tiere wie ein Hund eine dieser Klassen zugewiesen werden.
    Alle klassifizierten Tiere werden hierbei dieselben Eigenschaftsklassen mit unterschiedlichen Werten zugewiesen.
    Das heißt, dass einem Hund oder einer Taube die Anzahl der Beine und die Reproduktion zugewiesen werden, jedoch mit jeweils unterschiedlichen Werten.\\
    
    Durch die in Kapitel \ref{Messdaten} beschriebene Erhebung der Daten, werden die Stromdaten in einem bestimmten Format von der API bereitgestellt.
    Es werden 2 verschiedene Listen zurückgegeben wobei eine die reinen Messdaten enthält und die andere die Labels für diese Daten.\\
    Die reinen Messdaten werden zusammengetragen, indem zu den gelabelten Zeiträumen jeweils alle sekündlich gemessenen Werte des Stromnetzes als eine Matrix eingefügt werden.
    \newline

    \noindent
    Zusätzlich zu den manuell klassifizierten Daten werden noch zufällig ausgewählte Zeitabschnitte hinzugefügt um die Möglichkeit "`kein Gerät war aktiv"' abzubilden.
    Diese Abschnitte werden gewählt, indem zufällig Daten aus der Datenbank gewählt werden bei denen mit großer Wahrscheinlich kein zu klassifizierendes Gerät aktiv war.
    Eine dieser Zeiträume könnte zum Beispiel von 00:00 bis 5:00 Uhr, da zu dieser mit hoher Wahrschinelichkeit kein Gerät aktiv war.
    \newline

    \noindent
    Somit ergibt sich eine drei dimensionale Matrix welche in der ersten Dimension die Zeiträume abbildet, in der zweiten Dimension die sekündliche Zeitreihe und die dritte die vorhandenen physikalischen Größen.

    \begin{lstlisting}[language=Python, caption={Datenstruktur der gelabelten Messdaten, die von der API bereit gestellt wird},label=lst:DatenstrukturGelabelteMessdaten]

[
    [
        [u, f, h3, h5, h7, h9, h11, h13, h15],
        [u, f, h3, h5, h7, h9, h11, h13, h15],
        [u, f, h3, h5, h7, h9, h11, h13, h15],
        ...
    ]
]
    \end{lstlisting}

    Da Neuronale Netze feste Eingabegrößen benötigen, werden die Daten in Batches aufgeteilt.
    Batches bedeutet, dass die Zeitreihe in gleich große Abschnitte aufgeteilt wird.
    Dementsprechend wird die Matrix \( A[m, n, 9] \), zu einer Matrix mit einheitlicher Größe transfomiert, sodass die enstehende Matrix zum Beispiel die Form \( B[m, 20, 9] \) annimt.
    \newline

    \noindent
    Um diese neue Matrix zu erhalten wird folgender Algorithmus auf die alte Matrix angewandt:

    \begin{algorithm}\label{alg:BatchGenerierung}
        \caption{Batch Generierung}
        \begin{algorithmic}[1]
        \Function{GeneriereBatches}{$A,b$}
        \State\Comment{A - float[][][], b - int (Batchgröße)}
            \State ${B} = Array[][][]$
            \For{$i = 0$ to $length(A)$}
                \For{$j = 0$ to $length(A[i]) - b$}
                    \State $start = j$
                    \State $end = j + b$ 
                    \State $I_b = length(B) + 1$
                    \State $B[I_b] = A[i][start : end]$
                \EndFor
            \EndFor
            \State return $B$
        \EndFunction
        \end{algorithmic}
    \end{algorithm}

\section{Neuronales Netz}
    Wie Abschnitt \ref{ManuelleAnalyse} zeigt ist es möglich mit herkömmlichen manuellen Methoden verschiedene Geräte innerhalb eines Verlaufs zu klassifzieren.
    Somit sollte dies auch mit maschinellem Lernen möglich sein.
    \newline

    \noindent
    Um nun die Geräte maschinell zu klassifiziren, werden drei verschiedene "`neuronale Netz"' Modelle erstellt und miteinander verglichen.
    Die drei Modelle beinhalten ein "`Recurrent Neural Network(RNN) "', ein "`Convolutional Neural Network(CNN)"' sowie eine Mischung aus diesen Ansätzen. 
    Bei allen Modellen wurde als Gradientenverfahren die Adam-Optimierung gewählt, da diese bei mehr Rechenaufwand bessere Ergebnisse erzielt.    

    \subsubsection{CNN}
    Grundlegend besteht das \ac{CNN} aus einem "`Input Layer"', drei "`Convolutional Layers"', einem "`Dropout Layer"' sowie einem "`Output Layer"'.
    \newline

    \noindent
    Das "`Input Layer"' ist der Eingang zum neuronalen Netz, welcher die Rohdaten annimmt und an das eigentliche Netz weiterleitet. 
    Es ist ein weiteres "`Convolutional Layer"' und nimmt einen Eingabe-Tensor (Matrix innerhalb eines neuronalen Netzes), welcher an die Batchgröße angepasst ist.
    Dementsprechend hat der Eingabetensor die Form \( A[m, b, 9] \), mit m: Trainingsdatengröße und b: Batchgröße.
    \newline

    \noindent
    Die Eingabe wird dann weitergeleitet an die drei "`Convolutional Layers"', welche mit unterschiedlicher "`Hidden Layer"'-Größe initialisiert werden.
    Wobei die "`Hidden Layer"' größer werden je näher sie topologisch an dem "`Output Layer"' liegen.
    \newline

    \noindent
    Das "`Dropout Layer"' wird eingefügt um die Tensordimension zu verkleinern und somit das Ergebnis zu generalisieren und Overfitting zu vermeiden.
    \newline

    \noindent
    Das "`Output Layer"' wandelt nun die Erkenntnisse der vorherigen Schichten in ein lesbares Fomat um. 
    Hierzu wird ein "`Dense Layer"' verwendet, welcher ein eindimensionaler Tensor mit einem Feld pro klassifizierbaren Objekt ist und die Softmax-Funktion als Aktivierungsfunktion beinhaltet.
    Dieser eindimensionale Tensor repräsentiert pro Feld die Ausgabe pro zu klassifizierendem Gerät.     
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=\textwidth]{CNN_Model}
        \caption{Convolutional Neural Network}
        \label{fig:CNN_MODEL}
    \end{figure}

    \subsubsection{RNN}
    Das "`Recurrent Neural Network(RNN) "'- Model besteht aus einem "`Input Layer"', zwei darauffolgende "`LSTM(Long short-term memory) Layer"' und einem "`Ouput Layer"'.\\
    \noindent
    Das "`Input Layer"' ist ein weitereres "`LSTM Layer"' welche denselben Eingabetensor annimt, wie das CNN-Model.\\
    \noindent
    Es folgen zwei weitere "`LSTM Layer"' einer "`Hidden Layer"'-Größe von 64 pro Schicht.
    Dieselbe Größe wird auch im Eingabe-"`LSTM Layers"' verwendet.
    \newline

    \noindent
    Das "`Output Layer"' ist, wie beim \ac{CNN}-Model, ein "`Dense Layer"', der aus der Berechnung des Netzes eine verwertbare Ausgabe erzeugt.

    \begin{figure}[H]
        \centering
        \includegraphics[width=\textwidth]{RNN_Model}
        \caption{Recurrent Neural Network}
        \label{fig:RNN_MODEL}
    \end{figure}

    \subsubsection{Mixed - CNN und RNN}
    Das dritte zu testende Model beinhaltet eine Mischung aus den zwei bisherigen Netzen. 
    Dies soll zeigen, ob verschiedene Eigenschaften von neuronalen Netzen, positive oder negative Auswirkungen auf das Training und die Genauigkeit des Models haben.
    \newline

    \noindent
    Da dieses Model eine Mischform aus \ac{CNN} und \ac{RNN} ist, besteht diese Model aus zwei "`Convolutional Layers"', welche die Eingabe und eine Vorprozessierung zum Generalisieren der Eingabe darstellt.
    Auf diese beiden Schichten folgen nun zwei rekurrente "`LSTM Layer"' und dasselbe "`Output Layer"' wie bei beiden anderen Modellen.
    Die \ac{RNN}-Schichten sollen nun das Vorprozessierte verarbeiten und mögliche Muster in der Zeitserie erkennen.     

    \begin{figure}[H]
        \centering
        \includegraphics[width=\textwidth]{MIX_Model}
        \caption{Convolutional Neural Network with Recurrent Neural Network}
        \label{fig:MIX_MODEL}
    \end{figure}

    Die in diesem Abschnitt dargestellten Modelle stellen den Grundlegenden Aufbau der neuronalen Netze dar.
    Diese beinhalten jedoch keinerlei Wissen und können somit noch nicht zum Klassifizieren verwendet werden.    
    % batches von 20 / 30 / 60
    % überlappende batches
    % 1 batch von 20 Datenpunkten pro sekunde --> mehr daten und höhere genauigkeit beim späteren klassifizieren
    % Untransformierte Daten
    % Ableitungen da Verlauf bzw. Kurve entscheidend und nicht rein Werte wie bei Bildern
    % Normalisieren auf Werte zwischen 0 und 1 um Matrizen besser auswerten zu können


\section{Trainingsprozess}
    Um die drei verschiedene Modelle anwenden zu können, muss diesen Modellen Wissen beigebracht werden.
    Dies geschieht durch Trainieren dieser Modelle mit den in Abschnitt \ref{VorbereitenDerDaten} vorbereiteten Daten(vgl. Abschnitt \ref{KlassifikationDerMessdaten}).
    Damit die Modelle bestmögliche Ergebnisse erzielen, wird der Trainigsporzess mit verschiedenen Traningsparameter sowie verschiedenen Daten durchlaufen.
    Die Trainigsparameter beinhalten die Batchgöße, die Lernrate, die Trainingsepochen, die Anzahl der zusätzlich gewählten Zeiträume sowie die genutzten physikalischen Größen.
    \newline

    \noindent
    Die Trainingsparameter aller Netze werden zunächst mit Standardparametern versehen.
    \newline
    \noindent
    Diese Standardparametern werden wie folgt festgelegt:\\
    \noindent
    Lernrate = 0.001\\
    \noindent
    Datentypen = ['u', 'h3', 'h5', 'h7', 'h9', 'h11', 'h13', 'h15']\\
    \noindent
    Batchgröße = 20\\
    \noindent
    Epochen = 30\\

    \noindent
    Um die Auswirkung einzelner Parameter auf das Trainingsergebnis sehen zu können wird jeweils ein Paramter verändert und verschiedene Werte dieses Paramters miteinander verglichen.
    \newline
    \noindent
    Als Maßstab der Beeinflussung eines Paramters auf das Ergebnis eines Mdels wird die Genauigkeit sowie die Validierungsgenauigkeit in Prozent gewählt.
    Diese Werte werden nach dem Training eines Models, anhand von Test- bzw. Validierungsdaten errechnet (vgl. Abschnitt \ref{Lernprozess}). 
    Somit kann mit der Genauigkeit das Erlernen der Traingsdaten überprüft werden, sowie mit der Validierungsgenauigkeit Over- bzw. Underfitting des Models nachgewiesen werden.
    \newline

    \noindent
    Nach einigen Trainigsversuchen (vgl. Tabelle \ref{tabl:ErgebnisAbleitung}) mit den Rohdaten wurde festgestellt, dass mit diesen Daten keine aussagekräftigen Ergebnisse erziehlt werden können.
    Als Lösung dieses Problems, werden nach einigen Versuchen zwei verschiedene Verfahren gewählt mit denen die Rohdaten transfomiert werden. \\
    \noindent
    Zum einen wird eine Normalisierung der Daten in Werte zwischen 0-1 durchgeführt, sodass größere Werte wie die Spannung, welche bei ca. 230V liegt, keinen höheren Einfluss auf das Ergebnis haben kann als die Frequenz.\\
    \noindent
    Zusätzlich werden die Ableitungen über alle Werte der Rohdaten berechnet.
    Dies führt dazu, dass vom neuronalen Netz der Verlauf der Kurve berücksichtigt wird um Geräte zu erkennen und nicht die reinen Rohwerte, welche je nach Netzwerk und aktueller Netzaktivität stark abweichen können.

    \begin{table}[H]
        \centering
        \begin{tabular}{|c|c|c|c|}
            \hline
            Model & Genauigkeit & Validierungsgenauigkeit \\
            \hline
            CNN & 85,69\% & 85,78\% \\
            \hline
            RNN & 87,99\% & 86,68\% \\
            \hline
            MIX & 48,13\% & 48,42\% \\
            \hline
        \end{tabular}
        \caption{Ergebnis: Ableitung}
        \label{tabl:ErgebnisAbleitung}
    \end{table}

    \section{Ergebnisse} \label{Ergebnisse}

    Wie die Ergebnisse des Traingsprozesses zeigen, unterscheiden sich die Ergebnisse der verschiedenen Netze stark.
    Auch zeigen die Ergebnisse gut wie sich verschiedene Parameter auf die Genauigkeit des Netztes auswirken.

    \subsubsection{Batchgröße}

    Lernrate = 0.001\\
    \noindent
    Datentypen = ['u', 'h3', 'h5', 'h7', 'h9', 'h11', 'h13', 'h15']\\
    \noindent
    Epochen = 30\\
    \noindent
    Ableitung = True\\

    \begin{table}[H]
        \centering
        \begin{tabular}{|c|c|c|c|}
            \hline
            Model & Batchgröße & Genauigkeit & Validierungsgenauigkeit \\
            \hline
            CNN & 20 & 96,62\% & 95,16\% \\
            \hline
            RNN & 20 & 84,68\% & 84,70\% \\ 
            \hline
            MIX & 20 & 89,53\% & 89,24\% \\ 
            \hline
            \hline
            CNN & 30 & 97,97\% & 95,05\% \\ 
            \hline
            RNN & 30 & 89,31\% & 89,02\% \\ 
            \hline
            MIX & 30 & 94,28\% & 92,96\% \\ 
            \hline
            \hline
            CNN & 40 & 98,85\% & 98,94\% \\ 
            \hline
            RNN & 40 & 92,85\% & 92,05\% \\
            \hline
            MIX & 40 & 96,90\% & 96,92\% \\ 
            \hline
            \hline
            CNN & 50 & 99,21\% & 96,95\% \\ 
            \hline
            RNN & 50 & 95,82\% & 96,21\% \\ 
            \hline
            MIX & 50 & 98,74\% & 98,79\% \\ 
            \hline
            \hline
            CNN & 60 & 99,49\% & 91,63\% \\ 
            \hline
            RNN & 60 & 96,61\% & 96,39\% \\ 
            \hline
            MIX & 60 & 99,17\% & 98,99\% \\
            \hline
        \end{tabular}
        \caption{Ergebnis: Batchgröße}
        \label{tabl:ErgebnisBatchsize}
    \end{table}

    \subsubsection{Epochen}

    Lernrate = 0.001\\
    \noindent
    Datentypen = ['u', 'h3', 'h5', 'h7', 'h9', 'h11', 'h13', 'h15']\\
    \noindent
    Batchgröße = 20\\
    \noindent
    Ableitung = True\\

    \begin{table}[H]
        \centering
        \begin{tabular}{|c|c|c|c|}
            \hline
            Model & Epochen & Genauigkeit & Validierungsgenauigkeit \\
            \hline
            CNN & 10 &  87,38\% & 87,36\%  \\ 
            \hline
            RNN & 10 &  82,01\% & 81,22\%  \\ 
            \hline
            MIX & 10 &  83,28\% & 82,76\% \\ 
            \hline
            \hline
            CNN & 20 &  93,93\% & 92,09\%  \\ 
            \hline
            RNN & 20 &  84,41\% & 84,00\% \\ 
            \hline
            MIX & 20 &  86,68\% & 86,15\%  \\ 
            \hline
            \hline
            CNN & 30 &  96,75\% & 95,72\%  \\ 
            \hline
            RNN & 30 &  84,88\% & 84,57\%  \\ 
            \hline
            MIX & 30 &  88,23\% & 87,87\%  \\ 
            \hline
            \hline
            CNN & 40 &  98,18\% & 96,76\% \\ 
            \hline
            RNN & 40 &  85,18\% & 84,46\%  \\ 
            \hline
            MIX & 40 &  90,90\% & 89,72\%  \\ 
            \hline
            \hline
            CNN & 50 &  98,86\% & 97,50\%  \\ 
            \hline
            RNN & 50 &  85,80\% & 84,80\%  \\ 
            \hline
            MIX & 50 &  91,93\% & 91,10\%  \\ 
            \hline
            \hline
            CNN & 60 &  99,15\% & 98,58\%  \\ 
            \hline
            RNN & 60 &  85,67\% & 85,66\%  \\ 
            \hline
            MIX & 60 &  94,09\% & 90,53\%  \\ 
            \hline
            \hline
            CNN & 70 &  99,39\% & 99,02\%  \\ 
            \hline
            RNN & 70 &  86,63\% & 86,09\%  \\ 
            \hline
            MIX & 70 &  94,52\% & 92,94\%  \\ 
            \hline
            \hline
            CNN & 80 &  99,57\% & 99,27\%  \\ 
            \hline
            RNN & 80 &  86,22\% & 86,81\%  \\ 
            \hline
            MIX & 80 &  95,56\% & 93,98\%  \\ 
            \hline
            \hline
            CNN & 90 &  99,89\% & 99,63\%  \\ 
            \hline
            RNN & 90 &  87,64\% & 86,67\%  \\ 
            \hline
            MIX & 90 &  95,96\% & 94,42\%  \\ 
            \hline
            \hline
            CNN & 100 & 99,49\% & 99,37\%  \\ 
            \hline
            RNN & 100 & 87,29\% & 86,43\%  \\ 
            \hline
            MIX & 100 & 97,39\% & 96,46\% \\
            \hline

        \end{tabular}
        \caption{Ergebnis: Epochen}
        \label{tabl:ErgebnisEpoch}
    \end{table}

    \subsubsection{Lernrate}

    Datentypen = ['u', 'h3', 'h5', 'h7', 'h9', 'h11', 'h13', 'h15']\\
    \noindent
    Batchgröße = 20\\
    \noindent
    Epochen = 30\\
    \noindent
    Ableitung = True\\

    \begin{table}[H]
        \centering
        \begin{tabular}{|c|c|c|c|}
            \hline
            Model & Lernrate & Genauigkeit & Validierungsgenauigkeit \\
            \hline
            CNN & 0.0001 & 97,13\% & 95,55\% \\
            \hline
            RNN & 0.0001 & 84,54\% & 84,91\% \\
            \hline
            MIX & 0.0001 & 88,45\% & 88,43\% \\
            \hline
            \hline
            CNN & 0.001  & 96,65\% & 93,85\% \\
            \hline
            RNN & 0.001  & 84,98\% & 84,34\% \\
            \hline
            MIX & 0.001  & 90,17\% & 89,02\% \\
            \hline
            \hline
            CNN & 0.01   & 96,91\% & 93,42\% \\
            \hline
            RNN & 0.01   & 84,67\% & 84,84\% \\
            \hline
            MIX & 0.01   & 89,71\% & 89,41\% \\
            \hline
            \hline
            CNN & 0.1    & 96,51\% & 95,50\% \\
            \hline
            RNN & 0.1    & 85,06\% & 84,62\% \\
            \hline
            MIX & 0.1    & 89,46\% & 88,51\% \\
            \hline
        \end{tabular}
        \caption{Ergebnis: Lernrate}
        \label{tabl:ErgebnisLernrate}
    \end{table}   


\section{Auswertung der Ergebnisse}

    \subsection{Auswertungsalgorithmus}\label{Auswertungsalgorithmus}
    Nach der Klassifikation der Batches mit einem der neuronalen Netze, sind für diese klassifizierten Batches mit n Datenpunkten für jeden Punkt n Klassifizerungen vorhandenen(vgl. Algorithmus \ref{alg:BatchGenerierung}).
    Somit muss diese Klassifikation ausgewertet werden um genau sagen zu können, zu welchen Datenpunkten(Zeitpunkten) welche Geräte aktiv waren und welches Gerät am wahrscheinlichsten aktiv war.
    Hierzu wird der Algorithmus in \ref{alg:Ergbnisauswertung} verwendet, welcher die Treffer sowie die genaue Wahrscheinlichkeit pro Klasse zu einem bestimmten Zeitpunkt berücksichtigt. 
    Dieser Algorithmus bestimmt die Anzahl der Gewinnerklassen(Klasse mit der höchsten Wahrscheinlichkeit) aller Batches in denen der bestimmte Datenpunkt vorhanden ist, und bestimmt nun aus dieser Anzahl wiederum die Gewinnerklasse(Klasse mit den meisten Treffern).
    Außerdem wird die Wahrscheinlichkeit aller Klassen in allen Batches des Datenpunktes summiert und wiederum die Gewinnerklasse bestimmt.
    Somit erhält man zwei verschiedene Gewinnerklassen, welche wiederum miteinander verglichen werden um die entgültige Gewinnerklasse zu bestimmen.
    \newline
    \noindent
    Der Vorteil dieses Verfahrens ist die Berücksichtung aller Klassifikationen sowie deren einzel Wahrscheinlichkeit, sodass sich eine genauere Klassifizierung ergibt, wie Abbildung \ref{fig:CNN_RawClassification} zeigt.
    \subsection{Auswertung}
    Nach Anwendung des in \ref{Auswertungsalgorithmus} beschriebenen Algorithmus ergeben sich die nachfolgenden Schaubilder der verschiedenene neuronalen Netze.
    Die Schaubilder zeigen die jeweiligen klassifizierten Geräte jeden Zeitpunktes von Schaubild \ref{fig:ResultClassificationPeriod}.
    Hierbei zeigt die x-Achse den Zeitpunkt und die y-Achse das Gerät, wobei y \= 0  "`Senseo Kaffemaschine"' und y \= 3 "`Kein aktives bekanntes Gerät"'.
    
    \begin{figure}[H]
        \centering
        \includegraphics[width=\textwidth]{ErgebnisPeriodeRohdaten}
        \caption{Spannungsverlauf in Volt von "`24.10.2017 15:29:44"' bis "`24.10.2017 15:41:57"'}
        \label{fig:ResultClassificationPeriod}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=\textwidth]{CNN_ErgebnisKlassifizierung}
        \caption{Klassifizierung mit CNN}
        \label{fig:CNN_RawClassification}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=\textwidth]{RNN_ErgebnisKlassifizierung}
        \caption{Klassifizierung mit RNN}
        \label{fig:RNN_RawClassification}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=\textwidth]{MIX_ErgebnisKlassifizierung}
        \caption{Klassifizierung mit Mixed RNN und CNN}
        \label{fig:MIX_RawClassification}
    \end{figure}
    
    
    \begin{algorithm}\label{alg:Ergbnisauswertung}
        \caption{Ergbnisauswertung}
        \begin{algorithmic}[1]
        \Function{EvaluatePrediction}{$P,b$}
            \State \Comment{P - int[][] (Ergebnis eines neuronalen Netzes), b - int (Batchgröße)}
            \State
            \State ${A} = int[ ]$
            \For{$i = 0$ to $length(P)$}
                \State
                \State // Hit-Punkte aller Klassen für einen Zeitpunkt
                \State $ClassesHit = int[ ]$
                \State // Wahrscheinlichkeit aller Klassen für einen Zeitpunkt
                \State $ClassesPerc = float[ ]$
                \State
                \If{$i < b$}
                    \State $start = 0$
                    \State $end = i$
                \Else
                    \State $start = i - b$
                    \State $end = i$
                \EndIf
                \State
                \For{$d = start$ to $end$}
                    \State $maxClassIndex = argmax(pred[d])$
                    \State $ClassesHit[maxClassIndex]++$

                    \For{$w = 0$ to $pred[d]$}
                        \State $ClassesPerc[w] = ClassesPerc[w] + pred[d][w]$
                    \EndFor
                \EndFor
                \State
                \State $A.append(EvaluateClasses(ClassesHit, ClassesPerc))$
                \State
            \EndFor
            \State return $A$
        \EndFunction
        \end{algorithmic}
    \end{algorithm}
    \begin{algorithm}
        \caption{Ergebnis-Klassen-Auswertung}
        \begin{algorithmic}[1]
        \Function{EvaluateClasses}{$ClassesHit, ClassesPerc$}
            \State \Comment{ClassesHit - int[], ClassesPerc - float[]}
            \State
            \State $MaxHitClass = argmax(ClassesHit)$
            \State $MaxPercClass = argmax(ClassesPerc)$
            \State
            \If{$MaxHitClass == MaxPercClass$}
                \State return $MaxHitClass$
            \Else
                \State
                \State $MaxHitClassPerc = ClassesHit[MaxHitClass] / Sum(ClassesHit) $
                \State $MaxPercClassPerc = MaxPercClass[MaxHitClass] / Sum(ClassesPerc) $
                \State
                \If{$$MaxHitClassPerc < MaxPercClassPerc$$}
                    \State return $MaxPercClass$
                \Else
                    \State return $MaxPercClass$
                \EndIf
            \EndIf
        \EndFunction
        \end{algorithmic}
    \end{algorithm}
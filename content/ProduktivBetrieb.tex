\chapter{Produktivbetrieb}
    Das in Kapitel \ref{Ergebnis} resultierende neuronale Netz sowie die Auswertung dessen Ergebnis kann bisher nur begrenzt genutzt werden.
    Um diese Funktionen produktiv einsetzten zu können wird eine Schnittstelle zur einfachen Verwendung benötigt.
    
    An diese Schnittstelle werden folgende weitere Vorraussetzungen gestellt.
    \begin{description}
        \item[Echzeitanalyse] Es soll möglich sein Daten beziehungsweise Batches in Echzeit zu analysieren.
        \item[Periodenanalyse] Es soll möglich sein für beliebige historische Zeiträume Geräte zu klassifizieren.
        \item[Performance] Es sollte möglich sein lange Zeitreihen mit sehr vielen Daten auch noch in annehmbarer Zeit auszuwerten. Zudem sollte es möglich sein Zeitreihen in Echtzeit zu analysieren.
        \item[Tests] Um Fehler zu verhindern und ein stabile und sicheres Programm zu entwickeln sollen wichtige fehleranfällige Funktionalitäten getestet werden.
    \end{description}
    
    \subsection{Implementierung}
        Als Schnittstelle wird eine Socket.IO-API anstatt einer gebräuchlicheren REST-API aufgrund von besserer Performance und Einheitlichkeit mit der Daten-API gewählt.
        Die Spezifikation dieser Schnittstelle wird, wie in Abschnitt \ref{API-Spezifikation} beschrieben, festgelegt. 
        Somit ist die Echtzeitanalyse sowie die Periodenanalyse mit möglichst wenig Mehraufwand abgebildet.
        \newline

        Durch das Verwenden von Tensorflow und dessen Unterstützungseinschränkungen\footnote{https://www.tensorflow.org/install/} stehen grundsätzlich zwei verschiedene Ansätze zur Wahl.
        Es ist möglich die Architektur auf Python, C oder GoLang aufzubauen.
        Da die Architektur die vorher beschriebenen Anforderungen erfüllen muss und eine einfache Benutzung der neuronalen Netze erlauben sollte, werden mögliche Architekturen auf diese Anforderungen geprüft.
        \newline

        Da der komplette Trainingsprozess bereits in Python implementiert wurde, werden erste Implementierung einfach dort getestet \footnote{https://github.com/schrodit/wesense-ml/tree/master/prod}.
        Jedoch ist Python schlecht geeignet für viele Anfragen mit großem Rechenaufwand, wie für die Vorbereitung der Daten erforderlich ist.
        Auch konnte das Auslagern der aufwendigen Rechenoperationen keine Daten in Echtzeit auswerten.
        Somit wird entschieden den produktiv Betrieb in GoLang zu implementieren.
        \newline

        Der Einsatz von GoLang kann alle benötigten Anforderungen erfüllen auch wenn die Einbindung sowie der Support von Tensorflow nicht so gut Ausfällt wie es bei Python der Fall ist.
        Jedoch kann mit GoLang die essentielle Performanceanforderung ohne Probleme erfüllt werden und auch die Stabilität sowie die Fehleranfälligkeit ist durch den Einsatz von GoLang erheblich verbessert.
        Die Implementierung (siehe \footnote{https://github.com/schrodit/wesense-ml/tree/master/go}) besteht aus drei essentiellen Bausteinen welche in Module(Packages) aufgeteilt sind.
        Diese drei Grundbausteine sind die Datentransformation, die Klassifikation sowie dem Socket.IO-Server.
        \newline

        Da im Datentransformation-Modul die essentiellen und Fehleranfälligen Funktionalitäten implementiert sind, sind Tests für dieses Modul besonders wichtig.
        Hier wird eine Testabdeckung von mehr als 70\% erreicht um die Funktionsfähigkeit dieser Funktionen sicherzustellen.
        \newline

        Um eine stabile, zuverlässige und fehlerfreie Applikation zu schaffen wird eine \ac{CI}-Umgebung eingeführt.
        Diese \ac{CI}-Umgebung führt bei jedem Commit alle Tests aus, kompiliert das Program und baut ein Docker-Container (siehe \footnote{https://github.com/schrodit/wesense-ml/blob/master/.drone.yml}) in einer isolierten gleichartigen Umgebung.
        Somit kann eine gleichbleibende gute Qualität der Applikation sichergestellt werden.
    
    \subsection{Deployment}
        Die Bereitstellung der API wird als Docker-Container realisiert.
        Diese Deployment-Strategie bietet viele Vorteile wie Abstraktion von anderen Programmen eines Systems bei wenig Performance-Verlust, welcher bei der Echtzeitanalyse von Nöten ist.
        Außerdem ermöglicht es ein automatisches Deployment mit automtischer Lastverteilung in weitere Docker-Umgebungen.
        Somit wird zur Bereitstellung der API nur eine Dockerumgebung benötigt und kann sehr einfach auf weitere Server portiert werden.
                

    \subsection{API-Spezifikation}\label{API-Spezifikation}
        \subsubsection{Single Batch}
        \paragraph{Input:}

            \begin{lstlisting}[language=json,firstnumber=1]
Topic: "single-batch"
{
    "data": [
        {
            "u": 230,
            "f": 230,
            "h3": 230,
            "h5": 230,
            "h7": 230,
            "h9": 230,
            "h11": 230,
            "h13": 230,
            "h15": 230,
        },
        .. x Batchsize
    ]
}
            \end{lstlisting}
        
            \paragraph{Output:}
        
            \begin{lstlisting}[language=json,firstnumber=1]
Topic: 'single-prediction'
{
    "data": float //- Prediction of Senseo
}
            \end{lstlisting}
    
        \subsubsection{Period}
            \paragraph{Input:}
    
                \begin{lstlisting}[language=json,firstnumber=1]
Topic: "period"
{
    "data": {
        "start": "DateTime2",
        "end": "DateTime2"
    }
}
                \end{lstlisting}
            
                \paragraph{Output:}
            
                \begin{lstlisting}[language=json,firstnumber=1]
Topic: 'period-prediction'
* Series of Predictions where 0: Senseo, 1: Microwave, 2: Bosch, 3: Undefined, for every second
{
    "data": [
        Int,
        ... end - start
        Int
    ]
}
                \end{lstlisting}
